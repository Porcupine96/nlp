{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:29:42.320253Z",
     "start_time": "2019-05-13T13:29:42.299860Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:31:40.882014Z",
     "start_time": "2019-05-13T13:31:40.843411Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from preprocess import preprocess_all\n",
    "from util import read_bills, read_stopwords, split_ttf\n",
    "from variants import variant_i, variant_ii, variant_iii, variant_iv\n",
    "\n",
    "from fasttext import prepare_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:31:11.239785Z",
     "start_time": "2019-05-13T13:31:11.220791Z"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:31:14.755292Z",
     "start_time": "2019-05-13T13:31:12.328018Z"
    }
   },
   "outputs": [],
   "source": [
    "bills = read_bills('../lab1/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:31:16.311038Z",
     "start_time": "2019-05-13T13:31:15.681630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not resolve header for 1996_400.txt\n"
     ]
    }
   ],
   "source": [
    "df = preprocess_all(bills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:31:17.398790Z",
     "start_time": "2019-05-13T13:31:17.370950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1178\n",
       "unique       2\n",
       "top       True\n",
       "freq       610\n",
       "Name: is_amendment, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_amendment'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:31:20.922913Z",
     "start_time": "2019-05-13T13:31:20.887424Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test, validation = split_ttf(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:31:21.593750Z",
     "start_time": "2019-05-13T13:31:21.561609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train      706\n",
      "test       236\n",
      "validation 236\n"
     ]
    }
   ],
   "source": [
    "print('train      {}'.format(len(train)))\n",
    "print('test       {}'.format(len(test)))\n",
    "print('validation {}'.format(len(validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:31:22.757258Z",
     "start_time": "2019-05-13T13:31:22.736953Z"
    }
   },
   "outputs": [],
   "source": [
    "variants = [\n",
    "    ('i', variant_i),\n",
    "    ('ii', variant_ii),\n",
    "    ('iii', variant_iii),\n",
    "    ('iv', variant_iv)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:31:49.007672Z",
     "start_time": "2019-05-13T13:31:45.484785Z"
    }
   },
   "outputs": [],
   "source": [
    "variant_dfs = {}\n",
    "\n",
    "for name, variant in variants:\n",
    "    v_train=variant(train)\n",
    "    v_validation=variant(validation)\n",
    "    v_test=variant(test)\n",
    "    \n",
    "    variant_dfs[name] = (v_train, v_validation, v_test)\n",
    "    \n",
    "    prepare_files(v_train, 'fast/{}_train.csv'.format(name))\n",
    "    prepare_files(v_validation, 'fast/{}_validation.csv'.format(name))\n",
    "    prepare_files(v_test, 'fast/{}_test.csv'.format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM + TF-IDF\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:07:28.356931Z",
     "start_time": "2019-05-13T12:07:28.284293Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from preprocess import extract_tokens\n",
    "from util import build_vocabulary\n",
    "from svm import teach_svm, evaluate, svm_show_scores\n",
    "from vis import plot_metrics_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T17:36:31.677648Z",
     "start_time": "2019-05-12T17:36:31.643241Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = read_stopwords('./stopwords-pl.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:55:40.846490Z",
     "start_time": "2019-05-13T12:55:36.592142Z"
    }
   },
   "outputs": [],
   "source": [
    "vocabulary = build_vocabulary(df, drop_threshold=1000, drop_exceptions=['\"ust.', '\"art.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T17:36:32.206577Z",
     "start_time": "2019-05-12T17:36:32.152971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_file</th>\n",
       "      <th>text</th>\n",
       "      <th>is_amendment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>706</td>\n",
       "      <td>706</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>706</td>\n",
       "      <td>706</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1997_684.txt</td>\n",
       "      <td>Art. 1.\\n\\nW ustawie z dnia 4 marca 1994 r. o ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bill_file                                               text  \\\n",
       "count            706                                                706   \n",
       "unique           706                                                706   \n",
       "top     1997_684.txt  Art. 1.\\n\\nW ustawie z dnia 4 marca 1994 r. o ...   \n",
       "freq               1                                                  1   \n",
       "\n",
       "       is_amendment  \n",
       "count           706  \n",
       "unique            2  \n",
       "top            True  \n",
       "freq            364  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:11:57.902812Z",
     "start_time": "2019-05-13T13:10:17.837781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 0.4915254237288136 for tol=1e-11, c=0.1, kernel=rbf, drop=0\n"
     ]
    }
   ],
   "source": [
    "clf, clf_metric, metrics = teach_svm(train, validation, df, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:14:25.861835Z",
     "start_time": "2019-05-13T13:14:20.227700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3034329215742603\n",
      "Recall:    0.5508474576271186\n",
      "F1 score:  0.3913124015930351\n"
     ]
    }
   ],
   "source": [
    "vocabulary = build_vocabulary(df, drop_threshold=0, drop_exceptions=['\"ust.', '\"art.'])\n",
    "svm_show_scores(clf, test, vocabulary, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:11:58.610892Z",
     "start_time": "2019-05-13T13:10:20.922Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_metrics_for('C', metrics, kernels=['rbf'])\n",
    "plot_metrics_for('tol', metrics, kernels=['rbf'])\n",
    "plot_metrics_for('drop_threshold', metrics, kernels=['rbf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T23:24:56.471397Z",
     "start_time": "2019-05-12T23:24:56.441906Z"
    }
   },
   "outputs": [],
   "source": [
    "from variants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T11:46:41.745335Z",
     "start_time": "2019-05-13T11:46:41.698010Z"
    }
   },
   "outputs": [],
   "source": [
    "import fastText\n",
    "\n",
    "from fasttext import prepare_files, teach_fasttext, fasttext_show_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T23:47:48.733898Z",
     "start_time": "2019-05-12T23:47:48.706253Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T11:21:04.371480Z",
     "start_time": "2019-05-13T11:21:00.764368Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:00:55.027857Z",
     "start_time": "2019-05-13T11:56:22.959681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier: i\n",
      "Score 0.5847457627118644 for lr=0.1, wordNgrams=1\n",
      "Score 0.5889830508474576 for lr=0.1, wordNgrams=2\n",
      "Score 0.826271186440678 for lr=0.6, wordNgrams=1\n",
      "Score 0.8601694915254238 for lr=1.1, wordNgrams=1\n",
      "Score 0.8728813559322034 for lr=1.6, wordNgrams=1\n",
      "Score 0.8771186440677965 for lr=2.1, wordNgrams=2\n",
      "Score 0.8813559322033898 for lr=2.1, wordNgrams=3\n",
      "Score 0.885593220338983 for lr=2.6, wordNgrams=2\n",
      "Score 0.8898305084745762 for lr=3.1, wordNgrams=3\n",
      "------------------------------------\n",
      "Training classifier: ii\n",
      "Score 0.559322033898305 for lr=0.1, wordNgrams=1\n",
      "Score 0.5635593220338984 for lr=0.1, wordNgrams=3\n",
      "Score 0.75 for lr=0.6, wordNgrams=1\n",
      "Score 0.7584745762711863 for lr=1.1, wordNgrams=2\n",
      "Score 0.7796610169491526 for lr=1.6, wordNgrams=2\n",
      "------------------------------------\n",
      "Training classifier: iii\n",
      "Score 0.5847457627118644 for lr=0.1, wordNgrams=1\n",
      "Score 0.5889830508474576 for lr=0.1, wordNgrams=2\n",
      "Score 0.614406779661017 for lr=0.1, wordNgrams=3\n",
      "Score 0.7033898305084746 for lr=0.6, wordNgrams=1\n",
      "Score 0.7161016949152541 for lr=1.1, wordNgrams=1\n",
      "Score 0.7245762711864406 for lr=1.1, wordNgrams=2\n",
      "Score 0.7330508474576272 for lr=2.1, wordNgrams=2\n",
      "------------------------------------\n",
      "Training classifier: iv\n",
      "Score 0.5805084745762712 for lr=0.1, wordNgrams=1\n",
      "Score 0.5847457627118644 for lr=0.6, wordNgrams=1\n",
      "Score 0.6016949152542372 for lr=1.1, wordNgrams=2\n",
      "Score 0.6059322033898306 for lr=2.1, wordNgrams=2\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "fasttext_results = {}\n",
    "for name, (v_train, v_validation, v_test) in variant_dfs.items():\n",
    "    print('Training classifier: {}'.format(name))\n",
    "    clf, metrics = teach_fasttext('fast/{}_train.csv'.format(name), 'fast/{}_validation.csv'.format(name))\n",
    "    fasttext_results[name] = (clf, metrics)\n",
    "    print('------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:04:43.393643Z",
     "start_time": "2019-05-13T12:04:42.669840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant i\n",
      "Precision: 0.8940040293514223\n",
      "Recall:    0.8940677966101694\n",
      "F1 score:  0.8940197076870566\n",
      "-----------------------------\n",
      "Variant ii\n",
      "Precision: 0.7623735727549287\n",
      "Recall:    0.7627118644067796\n",
      "F1 score:  0.7624876008107991\n",
      "-----------------------------\n",
      "Variant iii\n",
      "Precision: 0.7976569569789907\n",
      "Recall:    0.7966101694915254\n",
      "F1 score:  0.7969044256120528\n",
      "-----------------------------\n",
      "Variant iv\n",
      "Precision: 0.6158098972486198\n",
      "Recall:    0.6186440677966102\n",
      "F1 score:  0.6156156530408775\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, (clf, _) in fasttext_results.items():\n",
    "    print(\"Variant {}\".format(name))\n",
    "    _, _, test = variant_dfs[name]\n",
    "    fasttext_show_scores(clf, test)\n",
    "    print('-----------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flair \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:32:15.373029Z",
     "start_time": "2019-05-13T13:32:15.254330Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flair.data_fetcher'; 'flair' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3e3a2e8c0d65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_fetcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNLPTaskDataFetcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlairEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocumentLSTMEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocumentRNNEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStackedEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCharLMEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTokenEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flair.data_fetcher'; 'flair' is not a package"
     ]
    }
   ],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.embeddings import StackedEmbeddings, CharLMEmbeddings, TokenEmbeddings\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:20:30.377681Z",
     "start_time": "2019-05-13T13:17:17.414503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-13 15:17:17,469 Reading data from fast\n",
      "2019-05-13 15:17:17,471 Train: fast/i_train.csv\n",
      "2019-05-13 15:17:17,472 Dev: fast/i_validation.csv\n",
      "2019-05-13 15:17:17,473 Test: fast/i_test.csv\n"
     ]
    }
   ],
   "source": [
    "corpus = NLPTaskDataFetcher.load_classification_corpus(\n",
    "    Path('./fast'),\n",
    "    test_file='i_test.csv',\n",
    "    dev_file='i_validation.csv',\n",
    "    train_file='i_train.csv')\n",
    "\n",
    "word_embeddings = [\n",
    "    WordEmbeddings('pl')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-13T13:28:10.185Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of torch failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/ipython/7.2.0/libexec/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/Cellar/ipython/7.2.0/libexec/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 376, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/__init__.py\", line 81, in <module>\n",
      "    __all__ += [name for name in dir(_C)\n",
      "NameError: name '_C' is not defined\n",
      "]\n",
      "[autoreload of torch.tensor failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/ipython/7.2.0/libexec/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/Cellar/ipython/7.2.0/libexec/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 376, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/tensor.py\", line 20, in <module>\n",
      "    class Tensor(torch._C._TensorBase):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/tensor.py\", line 194, in Tensor\n",
      "    \"\"\")\n",
      "RuntimeError: method 'detach' already has a docstring\n",
      "]\n",
      "[autoreload of torch.functional failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/ipython/7.2.0/libexec/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/Cellar/ipython/7.2.0/libexec/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 376, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/functional.py\", line 391, in <module>\n",
      "    del torch.unique_dim\n",
      "AttributeError: unique_dim\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "document_embeddings = DocumentRNNEmbeddings(\n",
    "    word_embeddings,\n",
    "    hidden_size=512,\n",
    "    reproject_words=True,\n",
    "    reproject_words_dimension=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:23:31.477562Z",
     "start_time": "2019-05-13T13:23:31.432983Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-305-8cf67bf1df8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m classifier = TextClassifier(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdocument_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlabel_dictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_label_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     multi_label=False)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'document_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "classifier = TextClassifier(\n",
    "    document_embeddings,\n",
    "    label_dictionary=corpus.make_label_dictionary(),\n",
    "    multi_label=False)\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.train('./fast', max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
